{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import Image\n",
    "# from jupyterthemes import jtplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scipy import interp\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_room_type.G</th>\n",
       "      <th>assigned_room_type.H</th>\n",
       "      <th>assigned_room_type.I</th>\n",
       "      <th>assigned_room_type.K</th>\n",
       "      <th>assigned_room_type.L</th>\n",
       "      <th>deposit_type.Non_Refund</th>\n",
       "      <th>deposit_type.Refundable</th>\n",
       "      <th>customer_type.Group</th>\n",
       "      <th>customer_type.Transient</th>\n",
       "      <th>customer_type.Transient_Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138399</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046133</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147897</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278155</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119205 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hotel  is_canceled  lead_time  stays_in_weekend_nights  \\\n",
       "0           1            0   0.464043                 0.000000   \n",
       "1           1            0   1.000000                 0.000000   \n",
       "2           1            0   0.009498                 0.000000   \n",
       "3           1            0   0.017639                 0.000000   \n",
       "4           1            0   0.018996                 0.000000   \n",
       "...       ...          ...        ...                      ...   \n",
       "119200      0            0   0.031208                 0.105263   \n",
       "119201      0            0   0.138399                 0.105263   \n",
       "119202      0            0   0.046133                 0.105263   \n",
       "119203      0            0   0.147897                 0.105263   \n",
       "119204      0            0   0.278155                 0.105263   \n",
       "\n",
       "        stays_in_week_nights    adults  children  babies  is_repeated_guest  \\\n",
       "0                       0.00  0.036364       0.0     0.0                  0   \n",
       "1                       0.00  0.036364       0.0     0.0                  0   \n",
       "2                       0.02  0.018182       0.0     0.0                  0   \n",
       "3                       0.02  0.018182       0.0     0.0                  0   \n",
       "4                       0.04  0.036364       0.0     0.0                  0   \n",
       "...                      ...       ...       ...     ...                ...   \n",
       "119200                  0.10  0.036364       0.0     0.0                  0   \n",
       "119201                  0.10  0.054545       0.0     0.0                  0   \n",
       "119202                  0.10  0.036364       0.0     0.0                  0   \n",
       "119203                  0.10  0.036364       0.0     0.0                  0   \n",
       "119204                  0.14  0.036364       0.0     0.0                  0   \n",
       "\n",
       "        previous_cancellations  ...  assigned_room_type.G  \\\n",
       "0                          0.0  ...                     0   \n",
       "1                          0.0  ...                     0   \n",
       "2                          0.0  ...                     0   \n",
       "3                          0.0  ...                     0   \n",
       "4                          0.0  ...                     0   \n",
       "...                        ...  ...                   ...   \n",
       "119200                     0.0  ...                     0   \n",
       "119201                     0.0  ...                     0   \n",
       "119202                     0.0  ...                     0   \n",
       "119203                     0.0  ...                     0   \n",
       "119204                     0.0  ...                     0   \n",
       "\n",
       "        assigned_room_type.H  assigned_room_type.I  assigned_room_type.K  \\\n",
       "0                          0                     0                     0   \n",
       "1                          0                     0                     0   \n",
       "2                          0                     0                     0   \n",
       "3                          0                     0                     0   \n",
       "4                          0                     0                     0   \n",
       "...                      ...                   ...                   ...   \n",
       "119200                     0                     0                     0   \n",
       "119201                     0                     0                     0   \n",
       "119202                     0                     0                     0   \n",
       "119203                     0                     0                     0   \n",
       "119204                     0                     0                     0   \n",
       "\n",
       "        assigned_room_type.L  deposit_type.Non_Refund  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "...                      ...                      ...   \n",
       "119200                     0                        0   \n",
       "119201                     0                        0   \n",
       "119202                     0                        0   \n",
       "119203                     0                        0   \n",
       "119204                     0                        0   \n",
       "\n",
       "        deposit_type.Refundable  customer_type.Group  customer_type.Transient  \\\n",
       "0                             0                    0                        1   \n",
       "1                             0                    0                        1   \n",
       "2                             0                    0                        1   \n",
       "3                             0                    0                        1   \n",
       "4                             0                    0                        1   \n",
       "...                         ...                  ...                      ...   \n",
       "119200                        0                    0                        1   \n",
       "119201                        0                    0                        1   \n",
       "119202                        0                    0                        1   \n",
       "119203                        0                    0                        1   \n",
       "119204                        0                    0                        1   \n",
       "\n",
       "        customer_type.Transient_Party  \n",
       "0                                   0  \n",
       "1                                   0  \n",
       "2                                   0  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "...                               ...  \n",
       "119200                              0  \n",
       "119201                              0  \n",
       "119202                              0  \n",
       "119203                              0  \n",
       "119204                              0  \n",
       "\n",
       "[119205 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data.columns\n",
    "dropvar = ['assigned_room_type.P', 'reserved_room_type.P','reservation_status_date']\n",
    "data = data.drop(dropvar, axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajdusted Ridge Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data[['is_canceled']]\n",
    "xdrop = ['is_canceled','Meal.BB','arrival_date_month.November','arrival_date_month.August',\n",
    "        'arrival_date_month.April','arrival_date_month.October']\n",
    "x_1 = data.drop(xdrop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajdusted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1,y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.1s\n",
      "/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.3min finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='auto', n_jobs=None,\n",
       "                                                penalty='l2', random_state=None,\n",
       "                                                solver='lbfgs', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.009, 0.01, 0.09, 1, 2, 3,\n",
       "                                              4, 5, 8, 9, 10, 25],\n",
       "                                        'max_iter': range(100, 1000, 100),\n",
       "                                        'penalty': ['l1', 'l2']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [0.001,.009,0.01,.09,1,2,3,4,5,8,9,10,25]\n",
    "\n",
    "max_iter = range(100,1000,100)\n",
    "\n",
    "log_grid = {'C': C,\n",
    "               'max_iter':max_iter,\n",
    "               'penalty': penalty,\n",
    "\n",
    "              }\n",
    "\n",
    "log = LogisticRegression()\n",
    "log_random = RandomizedSearchCV(estimator = log, param_distributions = log_grid, n_iter = 50, cv = 4, verbose=2, random_state=0, n_jobs = -1)\n",
    "log_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'max_iter': 300, 'C': 25}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_random.best_params_\n",
    "#'penalty': 'l2', 'max_iter': 300, 'C': 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.5719656306052405\n",
      "f1: 0.7068882334506493\n",
      "precision: 0.8314318543323802\n",
      "recall: 0.614798022766599\n",
      "AUC: 0.7706772553227448\n"
     ]
    }
   ],
   "source": [
    "##LOG\n",
    "log_best_par = LogisticRegression(penalty = 'l2', C = 25, max_iter = 1000)\n",
    "kappa = []\n",
    "rmse = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "AUC = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_1,y_1):\n",
    "    x_train, x_test = x_1[x_1.index.isin(train_index)], x_1[x_1.index.isin(test_index)]\n",
    "    y_train, y_test = y_1[y_1.index.isin(train_index)], y_1[y_1.index.isin(test_index)]\n",
    "    log_best_par.fit(x_train, y_train)\n",
    "    log_best_par_pred = log_best_par.predict(x_test)\n",
    "    #Evaluation Report\n",
    "    kappa.append(metrics.cohen_kappa_score(y_test, log_best_par_pred))\n",
    "    f1.append(metrics.f1_score(y_test, log_best_par_pred))\n",
    "    rmse.append(sqrt(metrics.mean_squared_error(y_test, log_best_par_pred)))\n",
    "    precision.append(metrics.precision_score(y_test, log_best_par_pred))\n",
    "    recall.append(metrics.recall_score(y_test, log_best_par_pred))\n",
    "    AUC.append(metrics.roc_auc_score(y_test, log_best_par_pred))\n",
    "print('kappa: {}'.format(np.mean(kappa)))\n",
    "print('f1: {}'.format(np.mean(f1)))\n",
    "print('precision: {}'.format(np.mean(precision)))\n",
    "print('recall: {}'.format(np.mean(recall)))\n",
    "print('AUC: {}'.format(np.mean(AUC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RandomizedSearchCV RF\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1,y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 59.4min finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'min_samples_split': range(2, 11),\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RandomizedSearchCV RF\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = range(2,11)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = range(2,11)\n",
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf\n",
    "#                'bootstrap': bootstrap,\n",
    "#               'criterion': criterion\n",
    "              }\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600, 'min_samples_split': 3, 'max_depth': 60}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n",
    "#'n_estimators': 600, 'min_samples_split': 3, 'max_depth': 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.7015830590008492\n",
      "f1: 0.8055655669563845\n",
      "precision: 0.8571080829794434\n",
      "recall: 0.7598822102373413\n",
      "AUC: 0.8426194030983887\n"
     ]
    }
   ],
   "source": [
    "##RF\n",
    "rf_best_par = RandomForestClassifier(n_estimators = 1000, min_samples_split = 3, max_depth = 60)\n",
    "kappa = []\n",
    "rmse = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "AUC = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_1,y_1):\n",
    "    x_train, x_test = x_1[x_1.index.isin(train_index)], x_1[x_1.index.isin(test_index)]\n",
    "    y_train, y_test = y_1[y_1.index.isin(train_index)], y_1[y_1.index.isin(test_index)]\n",
    "    rf_best_par.fit(x_train, y_train)\n",
    "    rf_best_par_pred = rf_best_par.predict(x_test)\n",
    "    #Evaluation Report\n",
    "    kappa.append(metrics.cohen_kappa_score(y_test, rf_best_par_pred))\n",
    "#     kappa.append(kappa)\n",
    "    f1.append(metrics.f1_score(y_test, rf_best_par_pred))\n",
    "#     f1.append(f1)\n",
    "    rmse.append(sqrt(metrics.mean_squared_error(y_test, rf_best_par_pred)))\n",
    "#     rmse.append(rmse)\n",
    "    precision.append(metrics.precision_score(y_test, rf_best_par_pred))\n",
    "    recall.append(metrics.recall_score(y_test, rf_best_par_pred))\n",
    "    AUC.append(metrics.roc_auc_score(y_test, rf_best_par_pred))\n",
    "# print('kappa',np.mean(kappa), 'f1', np.mean(f1), 'rmse', np.mean(rmse),'precision', np.mean(precision), 'recall', np.mean(recall),\n",
    "#      'AUC', np.mean(AUC))\n",
    "print('kappa: {}'.format(np.mean(kappa)))\n",
    "print('f1: {}'.format(np.mean(f1)))\n",
    "print('precision: {}'.format(np.mean(precision)))\n",
    "print('recall: {}'.format(np.mean(recall)))\n",
    "print('AUC: {}'.format(np.mean(AUC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1,y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=50. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  24 | elapsed:    2.3s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    2.6s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'var_smoothing': [1e-11, 1e-10, 1e-09,\n",
       "                                                          1e-08, 1e-07,\n",
       "                                                          1e-06]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RandomizedSearchCV GNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "var_smoothing = [1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6]\n",
    "\n",
    "# Create the random grid\n",
    "gnb_grid = {'var_smoothing': var_smoothing}\n",
    "\n",
    "gnb_random = RandomizedSearchCV(estimator = gnb, param_distributions = gnb_grid, n_iter = 50, cv = 4, verbose=2, random_state=0, n_jobs = -1)\n",
    "gnb_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-11}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.2028622068151403\n",
      "f1: 0.5932135605768448\n",
      "precision: 0.44997863658409154\n",
      "recall: 0.873333686984756\n",
      "AUC: 0.620635169865619\n"
     ]
    }
   ],
   "source": [
    "##GNB\n",
    "gnb_best_par = GaussianNB(var_smoothing = 1e-11)\n",
    "kappa = []\n",
    "rmse = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "AUC = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_1,y_1):\n",
    "    x_train, x_test = x_1[x_1.index.isin(train_index)], x_1[x_1.index.isin(test_index)]\n",
    "    y_train, y_test = y_1[y_1.index.isin(train_index)], y_1[y_1.index.isin(test_index)]\n",
    "    gnb_best_par.fit(x_train, y_train)\n",
    "    gnb_best_par_pred = gnb_best_par.predict(x_test)\n",
    "    #Evaluation Report\n",
    "    kappa.append(metrics.cohen_kappa_score(y_test, gnb_best_par_pred))\n",
    "    f1.append(metrics.f1_score(y_test, gnb_best_par_pred))\n",
    "    rmse.append(sqrt(metrics.mean_squared_error(y_test, gnb_best_par_pred)))\n",
    "    precision.append(metrics.precision_score(y_test, gnb_best_par_pred))\n",
    "    recall.append(metrics.recall_score(y_test, gnb_best_par_pred))\n",
    "    AUC.append(metrics.roc_auc_score(y_test, gnb_best_par_pred))\n",
    "    \n",
    "print('kappa: {}'.format(np.mean(kappa)))\n",
    "print('f1: {}'.format(np.mean(f1)))\n",
    "print('precision: {}'.format(np.mean(precision)))\n",
    "print('recall: {}'.format(np.mean(recall)))\n",
    "print('AUC: {}'.format(np.mean(AUC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted Neutral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1,y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.4min\n",
      "/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 30.0min finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=False,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=200,\n",
       "                                           momentum=0.9, n_iter_no_change=10,\n",
       "                                           nesterovs_momentum=True, power_t=0.5,\n",
       "                                           random...\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['identity', 'logistic',\n",
       "                                                       'tanh', 'relu'],\n",
       "                                        'alpha': [1e-05, 1e-05, 0.0001, 0.001,\n",
       "                                                  0.01, 0.1],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'momentum': [0.1, 0.3, 0.6, 0.9, 1.0],\n",
       "                                        'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RandomizedSearchCV NN\n",
    "nn = MLPClassifier()\n",
    "\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "alpha = [0.00001, 0.00001 ,0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "momentum = [0.1,0.3,0.6,0.9,1.0]\n",
    "# Create the random grid\n",
    "nn_grid = {'solver': solver,\n",
    "          'activation': activation,\n",
    "          'alpha': alpha,\n",
    "          'learning_rate': learning_rate,\n",
    "          'momentum': momentum}\n",
    "\n",
    "nn_random = RandomizedSearchCV(estimator = nn, param_distributions = nn_grid, n_iter = 50, cv = 4, verbose=2, random_state=0, n_jobs = -1)\n",
    "nn_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'momentum': 1.0,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'alpha': 0.0001,\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.626711949954429\n",
      "f1: 0.7526633414362316\n",
      "precision: 0.8270670823351183\n",
      "recall: 0.6912315345132659\n",
      "AUC: 0.8028481401537613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "##NN\n",
    "nn_best_par = MLPClassifier(solver = 'adam', momentum = 1, learning_rate = 'adaptive', alpha = 0.0001, activation = 'relu')\n",
    "kappa = []\n",
    "rmse = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "AUC = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_1,y_1):\n",
    "    x_train, x_test = x_1[x_1.index.isin(train_index)], x_1[x_1.index.isin(test_index)]\n",
    "    y_train, y_test = y_1[y_1.index.isin(train_index)], y_1[y_1.index.isin(test_index)]\n",
    "    nn_best_par.fit(x_train, y_train)\n",
    "    nn_best_par_pred = nn_best_par.predict(x_test)\n",
    "    #Evaluation Report\n",
    "    kappa.append(metrics.cohen_kappa_score(y_test, nn_best_par_pred))\n",
    "    f1.append(metrics.f1_score(y_test, nn_best_par_pred))\n",
    "    rmse.append(sqrt(metrics.mean_squared_error(y_test, nn_best_par_pred)))\n",
    "    precision.append(metrics.precision_score(y_test, nn_best_par_pred))\n",
    "    recall.append(metrics.recall_score(y_test, nn_best_par_pred))\n",
    "    AUC.append(metrics.roc_auc_score(y_test, nn_best_par_pred))\n",
    "    \n",
    "print('kappa: {}'.format(np.mean(kappa)))\n",
    "print('f1: {}'.format(np.mean(f1)))\n",
    "print('precision: {}'.format(np.mean(precision)))\n",
    "print('recall: {}'.format(np.mean(recall)))\n",
    "print('AUC: {}'.format(np.mean(AUC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_1,y_1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': range(2, 11),\n",
       "                                        'min_samples_split': range(2, 11)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RandomizedSearchCV DEC\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = range(2,11)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = range(2,11)\n",
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "#                'bootstrap': bootstrap,\n",
    "#               'criterion': criterion\n",
    "              }\n",
    "\n",
    "dec = DecisionTreeClassifier()\n",
    "dec_random = RandomizedSearchCV(estimator = dec, param_distributions = random_grid, n_iter = 50, cv = 4, verbose=2, random_state=0, n_jobs = -1)\n",
    "dec_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 7,\n",
       " 'min_samples_leaf': 6,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa: 0.6011039174070156\n",
      "f1: 0.7375264333763266\n",
      "precision: 0.7993311664983512\n",
      "recall: 0.684670129157399\n",
      "AUC: 0.7917084741335121\n"
     ]
    }
   ],
   "source": [
    "##DEC\n",
    "DEC_best_par = DecisionTreeClassifier(min_samples_split = 4, min_samples_leaf = 2,\n",
    "                                     max_features = 'auto', max_depth = 30)\n",
    "kappa = []\n",
    "rmse = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "AUC = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=4, random_state=0, shuffle=True)\n",
    "for train_index, test_index in kf.split(x_1,y_1):\n",
    "    x_train, x_test = x_1[x_1.index.isin(train_index)], x_1[x_1.index.isin(test_index)]\n",
    "    y_train, y_test = y_1[y_1.index.isin(train_index)], y_1[y_1.index.isin(test_index)]\n",
    "    DEC_best_par.fit(x_train, y_train)\n",
    "    DEC_best_par_pred = DEC_best_par.predict(x_test)\n",
    "    #Evaluation Report\n",
    "    kappa.append(metrics.cohen_kappa_score(y_test, DEC_best_par_pred))\n",
    "    f1.append(metrics.f1_score(y_test, DEC_best_par_pred))\n",
    "    rmse.append(sqrt(metrics.mean_squared_error(y_test, DEC_best_par_pred)))\n",
    "    precision.append(metrics.precision_score(y_test, DEC_best_par_pred))\n",
    "    recall.append(metrics.recall_score(y_test, DEC_best_par_pred))\n",
    "    AUC.append(metrics.roc_auc_score(y_test, DEC_best_par_pred))\n",
    "    \n",
    "print('kappa: {}'.format(np.mean(kappa)))\n",
    "print('f1: {}'.format(np.mean(f1)))\n",
    "print('precision: {}'.format(np.mean(precision)))\n",
    "print('recall: {}'.format(np.mean(recall)))\n",
    "print('AUC: {}'.format(np.mean(AUC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
